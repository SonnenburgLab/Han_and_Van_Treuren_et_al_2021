{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook outlines the code used for Figure 3 classifiers. The first several cells are Figure 3a and the last Figure 3b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normal utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For building trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "def name_detection_id(d_id, chemical_info, condense=True):\n",
    "    '''Determine the name of a detection according to hardcoded rules.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d_id : str\n",
    "        The detection id.\n",
    "    chemical_info : pd.DataFrame\n",
    "        The chemical information dataframe.\n",
    "    condense : bool\n",
    "        If True (default) then reports only unique compound id's in final\n",
    "        string. Helpful when the library lists several co-eluting\n",
    "        stereoisomers.\n",
    "    '''\n",
    "\n",
    "    tmp = chemical_info.loc[(chemical_info['dname'] == d_id),\n",
    "                            ['Compound', 'Peak']]\n",
    "\n",
    "    name = []\n",
    "    for _, row in tmp.iterrows():\n",
    "        if pd.notnull(row[1]):\n",
    "            n = row[0] + '_' + row[1]\n",
    "        else:\n",
    "            n = row[0]\n",
    "        name.append(n)\n",
    "\n",
    "    if condense:\n",
    "        name = sorted(set(name))\n",
    "    else:\n",
    "        name = sorted(name)\n",
    "\n",
    "    return ','.join(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Metabolomics data\n",
    "# Combined sample database\n",
    "md_fp = '../supplemental_table_5.xlsx'\n",
    "md = pd.read_excel(md_fp, index_col=0, sheet_name='mf')\n",
    "\n",
    "# Chemical info\n",
    "cpd_lib_fp = '../Supplementary_Table_1_mz-rt_library.xlsx'\n",
    "ci = pd.read_excel(cpd_lib_fp, sheet_name='chemical_info', index_col=0)\n",
    "chemical_info = pd.read_excel(cpd_lib_fp, sheet_name='chemical_info')\n",
    "istds = ci.loc[['IS_' in i for i in ci['Compound']], :].index.values\n",
    "\n",
    "name_translator = {c: name_detection_id(c, chemical_info) for c in\n",
    "                   set(chemical_info['dname'].values)}\n",
    "\n",
    "# Taxonomic info\n",
    "sac_fp = '../supplemental_table_6.xlsx'\n",
    "taxonomies = pd.read_excel(sac_fp, index_col=0, sheet_name='full_taxonomy')\n",
    "\n",
    "# agg_md\n",
    "agg_md = md = pd.read_excel('../supplemental_table_7.xlsx', sheet_name='aggregated_md', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aggregated data\n",
    "base_fp = '../supplemental_table_7.xlsx'\n",
    "\n",
    "# metabolomics data\n",
    "raw_data = pd.read_excel(io=base_fp,\n",
    "                         sheet_name='foldchange.dmrvf.fa.ps',\n",
    "                         index_col=0)\n",
    "\n",
    "# setup\n",
    "mega_media_samples = ((agg_md['sample_type'] == 'supernatant') &\n",
    "                      (agg_md['media'] == 'mm'))\n",
    "\n",
    "ss_md = agg_md.loc[mega_media_samples, :]\n",
    "\n",
    "levels = ['phylum', 'class', 'order', 'family', 'genus', '_species',\n",
    "          'taxonomy']\n",
    "\n",
    "tmp = []\n",
    "for _, (genus, species, strain) in ss_md[['genus', 'species', 'strain']].iterrows():\n",
    "    if pd.isnull(species):\n",
    "        tmp.append('%s %s' % (genus, strain))\n",
    "    else:\n",
    "        tmp.append('%s %s' % (genus, species))\n",
    "ss_md['_species'] = tmp \n",
    "\n",
    "levels = ['phylum', 'class', 'order', 'family', 'genus', '_species',\n",
    "          'taxonomy']\n",
    "\n",
    " # Take MM samples only. Remove ISTDs.\n",
    "data = raw_data.loc[mega_media_samples,\n",
    "                    ~np.in1d(raw_data.columns, istds)]\n",
    "# We will remove data that is mostly nan - probably not good classification.\n",
    "# Fill the rest with 0's. Also create a copy of data for plotting. Don't remove\n",
    "# nan's here.\n",
    "data_rf = data.loc[:, data.isnull().sum(0) < 300].fillna(0)\n",
    "data_plots = data.loc[:, data_rf.columns]\n",
    "\n",
    "results = []\n",
    "for level in levels:\n",
    "    for forest_num in range(25):\n",
    "        # The label we are classifying.\n",
    "        labels = ss_md[level].copy()\n",
    "\n",
    "        train_data, test_data, train_labels, test_labels = \\\n",
    "            train_test_split(data_rf, labels, test_size=0.33)\n",
    "\n",
    "        # rf = RandomForestClassifier(n_estimators=50, max_depth=5, bootstrap=False,\n",
    "        #                             max_features=100)\n",
    "        n_labels = len(set(labels))\n",
    "        rf = RandomForestClassifier(n_estimators=50, max_depth=5,\n",
    "                                    bootstrap=False, max_features=100)\n",
    "\n",
    "        rf.fit(train_data, train_labels)\n",
    "\n",
    "        predictions = rf.predict(test_data)\n",
    "\n",
    "        correct = (predictions == test_labels).sum()\n",
    "        incorrect = len(predictions) - correct\n",
    "        results.append([level, forest_num, correct, incorrect])\n",
    "        print(level, forest_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This runs a sample classification like Figure 3b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Our target is phylum level classification as binary between Bacteroidetes and Other\n",
    "labels = ss_md['phylum'].copy()\n",
    "good_labels = ['Bacteroidetes']\n",
    "labels[~np.in1d(labels, good_labels)] = 'Other'\n",
    "\n",
    "# Take MM samples only. Remove ISTDs.\n",
    "data = raw_data.loc[mega_media_samples, ~np.in1d(raw_data.columns, istds)]\n",
    "\n",
    "# We will remove data that is mostly nan - probably not good classification.\n",
    "# Fill the rest with 0's. Also create a copy of data for plotting. Don't remove\n",
    "# nan's here.\n",
    "data_rf = data.loc[:, data.isnull().sum(0) < 300].fillna(0)\n",
    "data_plots = data.loc[:, data_rf.columns]\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = \\\n",
    "    train_test_split(data_rf, labels, test_size=0.33)\n",
    "\n",
    "# rf = RandomForestClassifier(n_estimators=50, max_depth=5, bootstrap=False,\n",
    "#                             max_features=100)\n",
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=5, bootstrap=False,\n",
    "                            max_features=50)\n",
    "rf.fit(train_data, train_labels)\n",
    "\n",
    "predictions = rf.predict(test_data)\n",
    "\n",
    "cm = confusion_matrix(test_labels, predictions, labels=rf.classes_)\n",
    "cm = pd.DataFrame(cm, index=rf.classes_, columns=rf.classes_)\n",
    "\n",
    "#These are the misses\n",
    "misses = ss_md.loc[test_data.index[(predictions != test_labels)]]\n",
    "\n",
    "# Learn the feature importance scores\n",
    "fi = pd.DataFrame(rf.feature_importances_, index=data_rf.columns,\n",
    "                  columns=['importance']).sort_values('importance',\n",
    "                                                      ascending=False)\n",
    "fi['cpd'] = [name_detection_id(i, chemical_info) for i in fi.index]\n",
    "\n",
    "m1 = (np.diag(cm) / cm.sum(1)).mean()\n",
    "m2 = np.diag(cm).sum() / cm.sum(1).sum()\n",
    "\n",
    "tmp1 = data_plots.loc[:, fi.index[:10]]\n",
    "tmp1['phylum'] = agg_md.loc[tmp1.index, 'phylum']\n",
    "\n",
    "tmp2 = tmp1.groupby('phylum').median()\n",
    "\n",
    "z = shc.linkage(tmp2, method='ward')\n",
    "d = shc.dendrogram(z)\n",
    "z2 = shc.linkage(tmp2.T, method='ward')\n",
    "d2 = shc.dendrogram(z2)\n",
    "hm_data = tmp2.iloc[d['leaves'], d2['leaves']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
