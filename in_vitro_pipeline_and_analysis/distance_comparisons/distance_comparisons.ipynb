{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code details the construction of the metabolic distance comparisons in Figure 2a-c and Extended Data Figure 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below create a dataframe that contains every pairwise distance for mega medium grown strains using the specified metabolomic distance matrices, the V4 region 16s, and the full length 16S. The also calculate common taxonomic ancestry and equivlance class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Create a tip renaming map so we can associate 16s features in the phylogenetic with their data\n",
    "_fp = 'taxonomy_to_display_name.txt'\n",
    "taxonomy_to_display_map = pd.read_csv(_fp, index_col=0, sep='\\t')\n",
    "tip_renaming_map = {t: d for t, d in zip(tmp.index, tmp['disp_name'])}\n",
    "\n",
    "# Create tip data pickle\n",
    "fp = '../supplemental_table_6.xlsx'\n",
    "taxonomies = pd.read_excel(fp, index_col=0, sheet_name='full_taxonomy')\n",
    "\n",
    "lvls = ['phylum', 'class', 'order', 'family', 'genus']\n",
    "\n",
    "tmp = pd.read_csv('taxonomy_to_display_name.txt', index_col=0, sep='\\t')\n",
    "tip_data = {}\n",
    "tip_translator = {}\n",
    "for tip in tmp.index:\n",
    "    tip_translator[tmp.loc[tip, 'disp_name']] = tip\n",
    "    tip_data[tip] = {'disp_name': tmp.loc[tip, 'disp_name']}\n",
    "    for lvl in lvls:\n",
    "        tip_data[tip][lvl] = taxonomies.loc[tip, lvl]\n",
    "#pickle.dump(open('./tipdata.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normal utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "from skbio.tree import TreeNode\n",
    "\n",
    "def _tlca(c1_levels, c2_levels):\n",
    "    levels = ['kingdom', 'phylum', 'class', 'order', 'family', 'genus',\n",
    "              'species', 'strain']\n",
    "    for i in range(1, 8):\n",
    "        if c1_levels[i] != c2_levels[i]:\n",
    "            return i - 1\n",
    "        else:\n",
    "            pass\n",
    "    return 7\n",
    "\n",
    "# Output file path for everything.\n",
    "BASE_OUT_FP = 'ward_metabolomics_linkage/'\n",
    "\n",
    "###\n",
    "# This part of the code actually generates the WL trees and colors them.\n",
    "###\n",
    "\n",
    "# Aggregated metadata\n",
    "agg_md = pd.read_excel(io='../supplemental_table_7.xlsx', sheet_name='aggregated_md', index_col=0)\n",
    "\n",
    "# Master sample database\n",
    "md = pd.read_excel(io='../supplemental_table_5.xlsx', index_col=0, sheet_name='mf')\n",
    "\n",
    "cpd_lib_fp = '../Supplementary_Table_1_mz-rt_library.xlsx'\n",
    "ci = pd.read_excel(cpd_lib_fp, sheet_name='chemical_info', index_col=0)\n",
    "chemical_info = pd.read_excel(cpd_lib_fp, sheet_name='chemical_info')\n",
    "\n",
    "istds = ci.loc[['IS_' in i for i in ci['Compound']], :].index.values\n",
    "\n",
    "# Taxonomic info\n",
    "sac_fp = '../supplemental_table_6.xlsx'\n",
    "taxonomies = pd.read_excel(sac_fp, index_col=0, sheet_name='full_taxonomy')\n",
    "\n",
    "# Use only mega media samples.\n",
    "mega_media_samples = ((agg_md['sample_type'] == 'supernatant') &\n",
    "                      (agg_md['media'] == 'mm'))\n",
    "\n",
    "ss_md = agg_md.loc[mega_media_samples, :]\n",
    "\n",
    "datasets = [(1, 'count.ps'),\n",
    "            (0, 'foldchange'),\n",
    "            (0, 'foldchange.fa.ps'),\n",
    "            (0, 'foldchange.dmrvf.fa.ps')]\n",
    "\n",
    "\n",
    "tmp_results = {}\n",
    "\n",
    "for _add_val, datafp in datasets:\n",
    "    sup_data = pd.read_excel(io='../supplemental_table_7.xlsx', sheet_name=datafp, index_col=0) + _add_val\n",
    "    \n",
    "    data = sup_data.loc[mega_media_samples, :].copy()\n",
    "    data = data.loc[:, ~np.in1d(data.columns, istds)]\n",
    "    data['taxonomy'] = ss_md.loc[data.index, 'taxonomy']\n",
    "    _cdata = data.groupby('taxonomy').agg('mean')\n",
    "\n",
    "    #assert (_cdata.index == row_strains).all()\n",
    "\n",
    "    for scale, cdata in zip(('linear', 'log'),\n",
    "                            (_cdata, np.log2(_cdata))):\n",
    "\n",
    "        nr, nc = cdata.shape\n",
    "        results = np.zeros((nr, nr))\n",
    "        #condensed_results = np.zeros(int(nr * (nr - 1) / 2))\n",
    "        condensed_results = []\n",
    "\n",
    "        for i in range(nr):\n",
    "            v_i = cdata.iloc[i, :]\n",
    "            v_i_mask = pd.notnull(cdata.iloc[i, :])\n",
    "            for j in range(i+1, nr):\n",
    "                v_j = cdata.iloc[j, :]\n",
    "                v_j_mask = pd.notnull(cdata.iloc[j, :])\n",
    "\n",
    "                shared_metabolites = v_i_mask & v_j_mask\n",
    "                d = euclidean(v_i[shared_metabolites], v_j[shared_metabolites])\n",
    "                results[i, j] = d\n",
    "\n",
    "        tmp_results[(datafp, scale)] = results\n",
    "        print(datafp, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row_strains = cdata.index.values.copy()\n",
    "\n",
    "nr, nc = results.shape\n",
    "rows = int(nr * (nr - 1) / 2)\n",
    "cols = len(datasets) * 2\n",
    "tmp_data = np.zeros((rows, cols))\n",
    "\n",
    "strain_data = []\n",
    "\n",
    "row = 0\n",
    "for i in range(nr):\n",
    "    strain_i = tip_renaming_map[row_strains[i]]\n",
    "    for j in range(i+1, nr):\n",
    "        strain_j = tip_renaming_map[row_strains[j]]\n",
    "        col = 0\n",
    "        for (_, datafp) in datasets:\n",
    "            for scale in ('linear', 'log'):\n",
    "                tmp_data[row, col] = tmp_results[(datafp, scale)][i, j]\n",
    "                col += 1\n",
    "        strain_data.append([row_strains[i], row_strains[j], strain_i, strain_j])\n",
    "        row += 1\n",
    "\n",
    "columns = ['c_lin', 'c_log', 'fc_lin', 'fc_log', 'fc_fa_ps_lin', 'fc_fa_ps_log',\n",
    "           'dmrvf_lin', 'dmrvf_log']\n",
    "r = pd.DataFrame(tmp_data, columns=columns)\n",
    "\n",
    "columns = ['s1', 's2', 'tip_s1', 'tip_s2']\n",
    "r2 = pd.DataFrame(strain_data, columns=columns)\n",
    "\n",
    "final = pd.concat((r2, r), axis=1)\n",
    "\n",
    "phylogenetic_tree = TreeNode.read('phylogenetic_tree.tr')\n",
    "phylo_ttds = phylogenetic_tree.tip_tip_distances()\n",
    "\n",
    "phylogenetic_tree_fl16s = TreeNode.read('mega_media_renamed_clustal_omega.tre')\n",
    "phylo_ttds_fl16s = phylogenetic_tree_fl16s.tip_tip_distances()\n",
    "\n",
    "tmp_v3v4 = np.zeros(final.shape[0])\n",
    "tmp_fl16s = np.zeros(final.shape[0])\n",
    "row = 0\n",
    "for t1, t2 in zip(final['tip_s1'], final['tip_s2']):\n",
    "    tmp_v3v4[row] = phylo_ttds[t1, t2]\n",
    "    \n",
    "    if (t1 in phylo_ttds_fl16s.ids) and (t2 in phylo_ttds_fl16s):\n",
    "        tmp_fl16s[row] = phylo_ttds_fl16s[t1, t2]\n",
    "    else:\n",
    "        tmp_fl16s[row] = np.nan\n",
    "    row += 1\n",
    "\n",
    "final['v3v4_d'] = tmp_v3v4\n",
    "final['fl16s_d'] = tmp_fl16s\n",
    "\n",
    "\n",
    "same_exp = []\n",
    "shares_exp = []\n",
    "for idx, (s1, s2) in final.loc[:, ['s1', 's2']].iterrows():\n",
    "    tmp1 = agg_md.index[agg_md['taxonomy'] == s1]\n",
    "    tmp2 = agg_md.index[agg_md['taxonomy'] == s2]\n",
    "    if (set(agg_md.loc[tmp1, 'experiment'].values) ==\n",
    "        set(agg_md.loc[tmp2, 'experiment'].values)):\n",
    "        same_exp.append(True)\n",
    "    else:\n",
    "        same_exp.append(False)\n",
    "\n",
    "    if len((set(agg_md.loc[tmp1, 'experiment'].values).intersection(\n",
    "            set(agg_md.loc[tmp2, 'experiment'].values)))) > 0:\n",
    "        shares_exp.append(True)\n",
    "    else:\n",
    "        shares_exp.append(False)\n",
    "\n",
    "\n",
    "final['same_exp'] = same_exp\n",
    "final['share_exp'] = shares_exp\n",
    "final['all_exps'] = True\n",
    "\n",
    "levels = ['kingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species',\n",
    "          'strain']\n",
    "_taxa_levels = {}\n",
    "for taxon in tip_renaming_map.keys():\n",
    "    _taxa_levels[taxon] = taxonomies.loc[taxon, levels]\n",
    "\n",
    "tmp = []\n",
    "for s1, s2 in zip(final['s1'], final['s2']):\n",
    "    tmp.append(_tlca(_taxa_levels[s1], _taxa_levels[s2]))\n",
    "\n",
    "final['tlca'] = tmp\n",
    "df = final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# `tlca` encodes the last common ancestor that taxa share in a given\n",
    "# comparison. 0 indicates that are in different phyla, 6 indicates they are\n",
    "# different only in their strain.\n",
    "equivalence_classes = ['Bacteria', 'Phylum', 'Class', 'Order', 'Family',\n",
    "                       'Genus', 'Species']\n",
    "eqcs = []\n",
    "subsets = []\n",
    "for sid, row in df.iterrows():\n",
    "    s1 = row['s1']\n",
    "    s2 = row['s2']\n",
    "    tlca = row['tlca']\n",
    "\n",
    "    s1_phylum = taxonomy.loc[s1, 'phylum']\n",
    "    s2_phylum = taxonomy.loc[s2, 'phylum']\n",
    "\n",
    "    if tlca == 0:\n",
    "        # These should be equivalent conditions\n",
    "        assert s1_phylum != s2_phylum\n",
    "        subset = 'All'\n",
    "    else:\n",
    "        assert s1_phylum == s2_phylum\n",
    "        subset = s1_phylum\n",
    "\n",
    "    eqc = equivalence_classes[tlca]\n",
    "\n",
    "    eqcs.append(eqc)\n",
    "    subsets.append(subset)\n",
    "\n",
    "tmp = df.copy()\n",
    "tmp['eqc'] = eqcs\n",
    "tmp['subset'] = subsets\n",
    "tmp.columns = ['bacteria1', 'bacteria2', 'tip_s1', 'tip_s2', 'c_lin', 'c_log',\n",
    "                'fc_ling', 'fc_log', 'fc_fa_ps_lin', 'fc_fa_ps_log',\n",
    "                'dmrvf_lin', 'metab_dist', 'short_16s_dist', 'long_16s_dist',\n",
    "                'tlca', 'same_exp', 'share_exp', 'eqc', 'subset']\n",
    "\n",
    "tmp.to_csv('distances.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell creates Fig. 2b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.nonparametric import smoothers_lowess as sl\n",
    "\n",
    "# Make palette\n",
    "colors = [plt.cm.plasma(i/7) for i in range(7)][::-1]\n",
    "nested_taxonomy = ['Species', 'Genus', 'Family', 'Order', 'Class', 'Phylum',\n",
    "                   'Bacteria']\n",
    "palette = {i: j for i, j in zip(nested_taxonomy, colors)}\n",
    "\n",
    "\n",
    "data_fp = 'distances.txt'\n",
    "data = pd.read_csv(data_fp, sep='\\t', index_col=0)\n",
    "data.columns = ['bacteria1', 'bacteria2', 'tip_s1', 'tip_s2', 'c_lin', 'c_log',\n",
    "                'fc_ling', 'fc_log', 'fc_fa_ps_lin', 'fc_fa_ps_log',\n",
    "                'dmrvf_lin', 'metab_dist', 'short_16s_dist', 'long_16s_dist',\n",
    "                'tlca', 'same_exp', 'share_exp', 'eqc', 'subset']\n",
    "\n",
    "plotting_data = data[data['share_exp'] == True].copy()\n",
    "\n",
    "\n",
    "plt.close('all')\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 10), sharey=True)\n",
    "\n",
    "ax1.set_axisbelow(True)\n",
    "ax1.grid(axis='y')\n",
    "ax2.set_axisbelow(True)\n",
    "ax2.grid(axis='y')\n",
    "\n",
    "le = sl.lowess(plotting_data['metab_dist'].values,\n",
    "               plotting_data['short_16s_dist'].values)\n",
    "ax1.plot(le[:, 0], le[:, 1], alpha=1.0, color='k', linewidth=4,\n",
    "         zorder=10)\n",
    "_ = sns.scatterplot(data=plotting_data, x='short_16s_dist', y='metab_dist',\n",
    "                    hue='eqc', palette=palette, linewidths=0, edgecolor='none',\n",
    "                    ax=ax1)\n",
    "ax1.legend().remove()\n",
    "\n",
    "ax1.vlines(x=[0.11], ymin=[0], ymax=[70], lw=1, color='gray', linestyle='--')\n",
    "\n",
    "\n",
    "ax1.set_yticks(np.arange(0, 70, 5))\n",
    "ax1.set_yticklabels(np.arange(0, 70, 5), fontsize=20)\n",
    "ax1.set_ylabel('Metabolomic distance', fontsize=24)\n",
    "\n",
    "ax1.set_xlabel('Phylogenetic distance\\n(V4 region 16s)', fontsize=24)\n",
    "ax1.set_xticks(np.arange(0, .45, 0.075))\n",
    "ax1.set_xticklabels(np.arange(0, .45, 0.075).round(3), fontsize=20)\n",
    "ax1.set_xlim(0, 0.33)\n",
    "ax1.set_ylim(0, 65)\n",
    "\n",
    "\n",
    "_ = sns.boxplot(data=plotting_data, x='eqc', y='metab_dist', hue='eqc',\n",
    "                 order=nested_taxonomy, hue_order=nested_taxonomy, ax=ax2,\n",
    "                 boxprops={'fill':None, 'linewidth':2, 'color':'black'},\n",
    "                 whiskerprops={'linewidth':2, 'color':'black', 'zorder':10},\n",
    "                 medianprops={'linewidth':2, 'color':'black', 'zorder':10},\n",
    "                 capprops={'linewidth':2, 'color':'black', 'zorder':10},\n",
    "                 showfliers=False, dodge=False)\n",
    "\n",
    "\n",
    "_ = sns.stripplot(data=plotting_data, x='eqc', y='metab_dist', hue='eqc',\n",
    "                  ax=ax2, hue_order=nested_taxonomy, jitter=True,\n",
    "                  dodge=False, zorder=0, palette=palette, alpha=1.0,\n",
    "                  order=nested_taxonomy)\n",
    "ax2.legend().remove()\n",
    "\n",
    "\n",
    "ax2.tick_params(width=0, axis='y')\n",
    "\n",
    "ax2.set_xticklabels(['Species', 'Genus', 'Family', 'Order', 'Class', 'Phylum',\n",
    "                     'Kingdom'], rotation=90, fontsize=20)\n",
    "ax2.set_xlabel('Last common rank', fontsize=24)\n",
    "ax2.set_ylabel('')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.02, bottom=0.2)\n",
    "\n",
    "\n",
    "fp = 'figure2bc.pdf'\n",
    "fig.savefig(fp, transparent=True, dpi=300)\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell does the permutation testing for Extended Data 5a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "###\n",
    "# Code for creating tip to tip distances\n",
    "###\n",
    "# _tree = TreeNode.read('phylogenetic_tree.tr')\n",
    "# muscle_tree = _tree.root_at_midpoint()\n",
    "\n",
    "# _tree = TreeNode.read('foldchange.dmrvf.fa.ps.txt.log.renamed_wl.tre')\n",
    "# metab_tree = _tree.root_at_midpoint()\n",
    "\n",
    "# tips1 = set([tip.name for tip in muscle_tree.tips()])\n",
    "# tips2 = set([tip.name for tip in metab_tree.tips()])\n",
    "\n",
    "# assert tips1 == tips2\n",
    "\n",
    "# muscle_dm = muscle_tree.tip_tip_distances()\n",
    "# metab_dm = metab_tree.tip_tip_distances()\n",
    "\n",
    "muscle_dm = pd.read_csv('muscle_dm.txt', sep='\\t', index_col=0)\n",
    "metab_dm = pd.read_csv('metab_dm.txt', sep='\\t', index_col=0)\n",
    "tip_data = pickle.load(open('tipdata.p', 'rb'))\n",
    "tip_translator = {v['disp_name']: k for k,v in tip_data.items()}\n",
    "\n",
    "# 200 is an arbitrary constant here - just larger than the largest distance\n",
    "# expected in either tree.\n",
    "assert 200 > max(metab_dm.values.max(), muscle_dm.values.max())\n",
    "diag = 200 * np.eye(muscle_dm.values.shape[0])\n",
    "\n",
    "muscle_features = np.array(muscle_dm.index)\n",
    "features = np.array(metab_dm.index)\n",
    "\n",
    "assert (muscle_features == features).all()\n",
    "\n",
    "tlevels = ['phylum', 'class', 'order', 'family', 'genus', 'species_', 'disp_name']\n",
    "\n",
    "# same shape, r,c equal\n",
    "r, c = np.triu_indices(metab_dm.shape[0], 1)\n",
    "wl_dists = metab_dm.values[r, c]\n",
    "\n",
    "r, c = np.triu_indices(muscle_dm.shape[0], 1)\n",
    "phylo_dists = muscle_dm.values[r, c]\n",
    "\n",
    "ntiles = [1, 2, 3, 4, 5, 10]\n",
    "wl_ntiles = np.percentile(wl_dists, ntiles)\n",
    "phylo_ntiles = np.percentile(phylo_dists, ntiles)\n",
    "\n",
    "nrows, ncols = metab_dm.shape\n",
    "\n",
    "tmp = []\n",
    "results = []\n",
    "for ntile_level, (wl_radius, phylo_radius) in enumerate(zip(wl_ntiles, phylo_ntiles)):\n",
    "    metab_nk = (metab_dm.values + diag <= wl_radius)\n",
    "    phylo_nk = (muscle_dm.values + diag <= phylo_radius)\n",
    "\n",
    "    for row in range(nrows):\n",
    "        metab_features = features[metab_nk[row]]\n",
    "        phylo_features = features[phylo_nk[row]]\n",
    "\n",
    "        if (metab_features.sum() == 0) or (phylo_features.sum() == 0):\n",
    "            pass\n",
    "        else:\n",
    "            for lvl in tlevels:\n",
    "                # Features are in the same order so we only have one set of labels.\n",
    "                mfeatures_at_lvl = np.array([tip_data[tip_translator[i]][lvl] for i in metab_features])\n",
    "                pfeatures_at_lvl = np.array([tip_data[tip_translator[i]][lvl] for\n",
    "                                             i in phylo_features])\n",
    "\n",
    "                feature_union = np.array(sorted(set(mfeatures_at_lvl).union(set(pfeatures_at_lvl))))\n",
    "\n",
    "                m_count = np.zeros(len(feature_union))\n",
    "                p_count = np.zeros(len(feature_union))\n",
    "                for idx, f in enumerate(feature_union):\n",
    "                    m_count[idx] = (mfeatures_at_lvl == f).sum()\n",
    "                    p_count[idx] = (pfeatures_at_lvl == f).sum()\n",
    "\n",
    "\n",
    "                c = np.vstack((m_count, p_count)).min(0).sum()\n",
    "                max_possible = min(m_count.sum(), p_count.sum())\n",
    "                fractional_c = c / max_possible\n",
    "\n",
    "                perm_count = 0\n",
    "                for iter in range(1000):\n",
    "                    n_perm_metab_features = len(metab_features)\n",
    "                    n_perm_phylo_features = len(phylo_features)\n",
    "                    _fm = np.arange(ncols)\n",
    "                    np.random.shuffle(_fm)\n",
    "                    fm = features[_fm[:n_perm_metab_features]]\n",
    "\n",
    "                    _fp = np.arange(ncols)\n",
    "                    np.random.shuffle(_fp)\n",
    "                    fp = features[_fp[:n_perm_phylo_features]]\n",
    "\n",
    "                    # Features are in the same order so we only have one set of labels.\n",
    "                    mfeatures_at_lvl = np.array([tip_data[tip_translator[i]][lvl] for\n",
    "                                                 i in fm])\n",
    "                    pfeatures_at_lvl = np.array([tip_data[tip_translator[i]][lvl] for\n",
    "                                                 i in fp])\n",
    "\n",
    "                    feature_union = np.array(sorted(set(mfeatures_at_lvl).union(set(pfeatures_at_lvl))))\n",
    "\n",
    "                    m_count = np.zeros(len(feature_union))\n",
    "                    p_count = np.zeros(len(feature_union))\n",
    "                    for idx, f in enumerate(feature_union):\n",
    "                        m_count[idx] = (mfeatures_at_lvl == f).sum()\n",
    "                        p_count[idx] = (pfeatures_at_lvl == f).sum()\n",
    "\n",
    "                    perm_c = np.vstack((m_count, p_count)).min(0).sum()\n",
    "                    max_possible_perm_c = min(m_count.sum(), p_count.sum())\n",
    "                    perm_fractional_c = perm_c / max_possible_perm_c\n",
    "\n",
    "                    if fractional_c < perm_fractional_c:\n",
    "                        perm_count += 1\n",
    "\n",
    "                results.append([features[row], ntile_level, wl_radius, phylo_radius,\n",
    "                                len(metab_features), len(phylo_features),\n",
    "                                len(feature_union), lvl, c, max_possible, fractional_c, perm_count])\n",
    "\n",
    "    print(row)\n",
    "\n",
    "data = pd.DataFrame(results, columns=['feature', 'ntile_level', 'wl_radius', 'phylo_radius',\n",
    "                                      'n_metab', 'n_phylo', 'n_union', 'level',\n",
    "                                      'c', 'max_possible', 'fractional_c', 'perm_c'])\n",
    "#data.to_csv('./extended_data_5a/extended_data_5a.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell creates the plot for Extended Data 5a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "out_fp = './extended_data_5a/'\n",
    "xlabels = ['Strain', 'Species', 'Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
    "levels = ['disp_name', 'species_', 'genus', 'family', 'order', 'class', 'phylum']\n",
    "for xlabel, level in zip(xlabels, levels):\n",
    "    plotting_data = data[(data['ntile_level'] == 3) &\n",
    "                         (data['level'] == level)]\n",
    "\n",
    "    xbins = [0, 50, 1000]\n",
    "    ybins = np.linspace(0, 1, 6)\n",
    "\n",
    "    xbinticklabels = ['p<=0.05', 'p>0.05']\n",
    "    ybinticklabels = ['%s-%s' % (ybins[i].round(2), (ybins[i] + 0.2).round(2))\n",
    "                      for i in range(5)]\n",
    "\n",
    "    c, x, y = np.histogram2d(plotting_data['perm_c'],\\\n",
    "                             plotting_data['fractional_c'], \n",
    "                             bins=(xbins, ybins))\n",
    "\n",
    "    fig = plt.figure(figsize=(2, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    sns.heatmap(c.T, square=True, xticklabels=xbinticklabels,\n",
    "                yticklabels=ybinticklabels,\n",
    "                annot=True, ax=ax, cbar=None, cmap=plt.cm.Reds,\n",
    "                annot_kws={'fontsize':20})\n",
    "    ax.set_title('%s' % xlabel, fontsize=20)\n",
    "    plt.subplots_adjust(left=0.55, bottom=0.25)\n",
    "    plt.setp(ax.get_xticklabels(), fontsize=20, rotation=90)\n",
    "    plt.setp(ax.get_yticklabels(), fontsize=20, rotation=0)\n",
    "    plt.savefig(out_fp + xlabel + '.pdf', dpi=300, transparent=True)\n",
    "    plt.close('all')\n",
    "\n",
    "sns.heatmap(c, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell demonstrates the linear models used in Supplementary Table 7 tab \"regression_results\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel(io='../supplemental_table_7.xlsx', sheet_name='distances', index_col=0)\n",
    "data.columns = ['bacteria1', 'bacteria2', 'tip_s1', 'tip_s2', 'c_lin', 'c_log',\n",
    "                'fc_ling', 'fc_log', 'fc_fa_ps_lin', 'fc_fa_ps_log',\n",
    "                'dmrvf_lin', 'metab_dist', 'short_16s_dist', 'long_16s_dist',\n",
    "                'tlca', 'same_exp', 'share_exp', 'eqc', 'subset']\n",
    "# Stats models sorts all the levels of a categorical variable and uses the\n",
    "# first entry (lexographically sorted) as the base case.\n",
    "data.loc[(data['eqc'] == 'Species').values, 'eqc'] = 'AAA_Species'\n",
    "data_1 = data[data['share_exp'] == True]\n",
    "\n",
    "# Example of distance constraint\n",
    "# data_1 = data[(data['share_exp'] == True) &\n",
    "#               (data['short_16s_dist'] >= 0.11)]\n",
    "\n",
    "f = 'metab_dist ~ eqc'\n",
    "\n",
    "q = smf.ols(f, data=data_2).fit()\n",
    "print(q.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
