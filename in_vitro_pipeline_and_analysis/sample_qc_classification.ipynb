{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs the code that was used to check for supernatants that appear to unusual given their phylum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normal utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For building trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "# Metabolomics data\n",
    "base_fp = 'supplemental_table_7.xlsx'\n",
    "log2_istdtic = np.log2(1 + pd.read_excel(io=base_fp, sheet_name='count.ps', index_col=0))\n",
    "\n",
    "fc = np.log2(1 + pd.read_excel(io=base_fp, sheet_name='foldchange', index_col=0))\n",
    "fc_fc = np.log2(1 + pd.read_excel(io=base_fp, sheet_name='foldchange.fa.ps_log2', index_col=0))\n",
    "\n",
    "# Because Seaborn is bad about interpreting numeric columns as discrete color\n",
    "# categories, we'll make some modifications here.\n",
    "j_agg_md = pd.read_excel(io=base_fp, sheet_name='aggregated_md', index_col=0)\n",
    "j_agg_md['str_exp'] = list(map(lambda x: 'exp_' + str(int(x)), \n",
    "                               j_agg_md['experiment']))\n",
    "\n",
    "# Master sample database\n",
    "master_sample_database_fp = 'supplemental_table_5.xlsx'\n",
    "md = pd.read_excel(io=master_sample_database_fp, index_col=0, sheet_name='mf')\n",
    "\n",
    "cpd_lib_fp = 'Supplementary_Table_1_mz-rt_library.xlsx'\n",
    "ci = pd.read_excel(cpd_lib_fp, sheet_name='chemical_info', index_col=0)\n",
    "chemical_info = pd.read_excel(cpd_lib_fp, sheet_name='chemical_info')\n",
    "\n",
    "istds = ci.loc[['IS_' in i for i in ci['Compound']], :].index.values\n",
    "\n",
    "# setup\n",
    "mega_media_samples = ((j_agg_md['sample_type'] == 'supernatant') &\n",
    "                      (j_agg_md['media'] == 'mm'))\n",
    "\n",
    "ss_md = j_agg_md.loc[mega_media_samples, :]\n",
    "\n",
    "\n",
    "# Alter the datasets so that istds and non-mm samples are eliminated\n",
    "data_log2_istdtic = log2_istdtic.loc[mega_media_samples,\n",
    "                                      ~np.in1d(log2_istdtic.columns, istds)]\n",
    "data_fc = fc.loc[mega_media_samples, ~np.in1d(fc.columns, istds)]\n",
    "data_fc_fc = fc_fc.loc[mega_media_samples, ~np.in1d(fc_fc.columns, istds)]\n",
    "\n",
    "\n",
    "assert (data_log2_istdtic.index == ss_md.index).all()\n",
    "assert (data_fc.index == ss_md.index).all()\n",
    "assert (data_fc_fc.index == ss_md.index).all()\n",
    "\n",
    "### Ordering variables we don't want to change\n",
    "DATASETS = [data_log2_istdtic, data_fc, data_fc_fc, data_log2_istdtic,\n",
    "            data_log2_istdtic, data_log2_istdtic, data_log2_istdtic,\n",
    "            data_log2_istdtic]\n",
    "# Make the dataset labels. The last 5 experiments are group vs 'Other'.\n",
    "PHYLUM_ORDER = ['Actinobacteria', 'Bacteroidetes', 'Firmicutes',\n",
    "                'Fusobacteria', 'Proteobacteria', 'Other']\n",
    "DATASET_LABELS = [ss_md['phylum'].copy(), ss_md['phylum'].copy(),\n",
    "                  ss_md['phylum'].copy()]\n",
    "for label in PHYLUM_ORDER[:-1]:\n",
    "    tmp_labels = ss_md['phylum'].copy()\n",
    "    tmp_labels[~np.in1d(tmp_labels, [label])] = 'Other'\n",
    "    DATASET_LABELS.append(tmp_labels)\n",
    "\n",
    "SAMPLE_TO_ROW_INDEXER = {sample_idx: row_idx for row_idx, sample_idx in\n",
    "                         enumerate(ss_md.index)}\n",
    "\n",
    "METABOLITE_ORDER = data_log2_istdtic.columns.copy()\n",
    "N_METABOLITES = METABOLITE_ORDER.shape[0]\n",
    "METABOLITE_TO_COL_INDEXER = {metabolite: col_idx for col_idx, metabolite in\n",
    "                             enumerate(METABOLITE_ORDER)}\n",
    "\n",
    "N_EXPERIMENTS = 8\n",
    "N_TRIALS = 80 \n",
    "TRIALS = ['trial%s' % str(trial).zfill(2) for trial in range(N_TRIALS)]\n",
    "\n",
    "# RF parameters\n",
    "FORESTS = 50\n",
    "TREES_PER_FOREST = 50\n",
    "MAX_DEPTH = 7\n",
    "MAX_FEATURES = 50\n",
    "\n",
    "\n",
    "# Create the collated accuracies data\n",
    "_cols = ['str_exp', 'media', 'c18positive', 'c18negative', 'hilicpositive',\n",
    "         'culture_source', 'taxonomy', 'phylum']\n",
    "\n",
    "collated_accuracies = ss_md[_cols].copy()\n",
    "\n",
    "for trial in TRIALS:\n",
    "    collated_accuracies[trial] = np.zeros(collated_accuracies.shape[0])\n",
    "\n",
    "collated_accuracies['accuracy'] = np.zeros(collated_accuracies.shape[0])\n",
    "\n",
    "# Per trial accuracies\n",
    "full_trial_results = {}\n",
    "\n",
    "# Trial parameters DF\n",
    "trial_parameters = pd.DataFrame(np.zeros((N_TRIALS, 2)), index=TRIALS, \n",
    "                                columns=['dataset', 'nfeatures'])\n",
    "\n",
    "# Trial feature importances\n",
    "trial_feature_importances = pd.DataFrame(np.zeros((N_TRIALS, N_METABOLITES)),\n",
    "                                         index=TRIALS,\n",
    "                                         columns=METABOLITE_ORDER)\n",
    "\n",
    "cur_trial_n = 0\n",
    "for exp_counter, (dataset, labels) in enumerate(zip(DATASETS, DATASET_LABELS)):\n",
    "    non_nan_thresholds = np.percentile(dataset.isnull().sum(0), \n",
    "                                       np.linspace(10, 100, 10))\n",
    "\n",
    "    for iter_counter, th in enumerate(non_nan_thresholds):\n",
    "        print('exp: %s\\ntrial: %s\\n' % (exp_counter, iter_counter))\n",
    "        cur_trial = 'trial%s' % str(cur_trial_n).zfill(2)\n",
    "        cur_trial_n += 1\n",
    "\n",
    "        data_rf = dataset.loc[:, dataset.isnull().sum(0) < round(th)].fillna(0)\n",
    "\n",
    "        # Data for the trial parameters\n",
    "        trial_parameters.loc[cur_trial] = [exp_counter, data_rf.shape[1]]\n",
    "\n",
    "        # Data for feature importances aggregated across the forests in this\n",
    "        # trial.\n",
    "        _feature_importances = np.zeros((FORESTS, N_METABOLITES))\n",
    "\n",
    "        _trial_results = []\n",
    "        for forest in range(FORESTS):\n",
    "            print('forest: %s' % forest)\n",
    "            train_data, test_data, train_labels, test_labels = \\\n",
    "                train_test_split(data_rf, labels, test_size=0.33)\n",
    "\n",
    "            # Number of features must be at least MAX_FEATURES.\n",
    "            _max_features = min(MAX_FEATURES, train_data.shape[1])\n",
    "            rf = RandomForestClassifier(n_estimators=TREES_PER_FOREST,\n",
    "                                        max_depth=MAX_DEPTH,\n",
    "                                        bootstrap=False,\n",
    "                                        max_features=_max_features)\n",
    "\n",
    "            rf.fit(train_data, train_labels)\n",
    "\n",
    "            predictions = rf.predict(test_data)\n",
    "\n",
    "            # Record feature importance data.\n",
    "            tmp = [METABOLITE_TO_COL_INDEXER[i] for i in train_data.columns]\n",
    "            _feature_importances[forest][tmp] = rf.feature_importances_.copy()\n",
    "\n",
    "            _trial_results.append((test_data.index, predictions))\n",
    "\n",
    "        # Calculate aggregate feature importance scores.\n",
    "        trial_feature_importances.loc[cur_trial] = _feature_importances.mean(0)\n",
    "\n",
    "\n",
    "        # Aggregate trial accuracies.\n",
    "        tmp = np.zeros((ss_md.shape[0], 6), dtype=np.float32)\n",
    "        col_indexer = {phylum: i for i, phylum in enumerate(PHYLUM_ORDER)}\n",
    "\n",
    "        for idxs, guesses in _trial_results:\n",
    "            for i, j in zip(idxs, guesses):\n",
    "                tmp[SAMPLE_TO_ROW_INDEXER[i], col_indexer[j]] += 1\n",
    "\n",
    "        trial_result = pd.DataFrame(tmp / np.expand_dims(tmp.sum(1), 1),\n",
    "                                    index=ss_md.index, \n",
    "                                    columns=PHYLUM_ORDER)\n",
    "        full_trial_results[cur_trial] = trial_result\n",
    "\n",
    "        tmp_accuracy = np.zeros(trial_result.shape[0])\n",
    "        for _idx in range(trial_result.shape[0]):\n",
    "            true_label = ss_md.iloc[_idx]['phylum']\n",
    "            tmp_accuracy[_idx] = trial_result.iloc[_idx,\n",
    "                                                   col_indexer[true_label]]\n",
    "        \n",
    "        collated_accuracies[cur_trial] = tmp_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
